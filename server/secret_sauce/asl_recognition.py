import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

class ASLRecognizer:
    def __init__(self, model_path=None):
        self.model = None
        self.class_names = []
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
        else:
            self.build_model()
    
    def build_model(self):
        """Build CNN model architecture"""
        model = models.Sequential([
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Flatten(),
            layers.Dropout(0.5),
            layers.Dense(128, activation='relu'),
            layers.Dense(26, activation='softmax')  # 26 letters in ASL
        ])
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.model = model
        return model
    
    def load_data(self, dataset_path):
        """Load images from dataset, including flipped folders"""
        images = []
        labels = []
        class_names = sorted([c for c in os.listdir(dataset_path) if c.isalpha() and len(c) == 1])
        self.class_names = class_names  # Store only original classes

        for idx, class_name in enumerate(class_names):
            for suffix in ['', '_flipped']:
                class_path = os.path.join(dataset_path, f"{class_name}{suffix}")
                if not os.path.isdir(class_path):
                    continue

                for img_file in os.listdir(class_path):
                    if not (img_file.lower().endswith(('.png', '.jpg', '.jpeg'))):
                        continue

                    img_path = os.path.join(class_path, img_file)
                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

                    if img is not None:
                        img = cv2.resize(img, (64, 64))
                        img = img / 255.0
                        images.append(img)
                        labels.append(idx)  # Same label whether flipped or not

        return np.array(images), np.array(labels)

    
    def preprocess_data(self, images, labels):
        """Preprocess the data and split into train/test sets"""
        # Reshape for CNN input
        images = images.reshape(images.shape[0], 64, 64, 1)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            images, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        return X_train, X_test, y_train, y_test
    
    def train(self, dataset_path, epochs=15, batch_size=32, save_path=None):
        """Train the model on the ASL dataset"""
        # Load and preprocess data
        print("Loading data...")
        images, labels = self.load_data(dataset_path)
        print(f"Loaded {len(images)} images across {len(self.class_names)} classes")
        
        X_train, X_test, y_train, y_test = self.preprocess_data(images, labels)
        
        # Data augmentation
        datagen = tf.keras.preprocessing.image.ImageDataGenerator(
            rotation_range=10,
            zoom_range=0.1,
            width_shift_range=0.1,
            height_shift_range=0.1
        )
        
        # Train model
        print("Training model...")
        history = self.model.fit(
            datagen.flow(X_train, y_train, batch_size=batch_size),
            epochs=epochs,
            validation_data=(X_test, y_test),
            callbacks=[
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_accuracy', 
                    patience=5,
                    restore_best_weights=True
                )
            ]
        )
        
        # Evaluate model
        print("Evaluating model...")
        test_loss, test_acc = self.model.evaluate(X_test, y_test)
        print(f"Test accuracy: {test_acc:.4f}")
        
        # Generate classification report
        y_pred = np.argmax(self.model.predict(X_test), axis=1)
        print("\nClassification Report:")
        report = classification_report(y_test, y_pred, target_names=self.class_names)
        print(report)
        
        # Plot confusion matrix
        plt.figure(figsize=(12, 10))
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.class_names, yticklabels=self.class_names)
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.title('Confusion Matrix')
        
        # Save the confusion matrix
        if save_path:
            plt.savefig(os.path.join(os.path.dirname(save_path), 'confusion_matrix.png'))
        
        plt.show()
        
        # Plot training history
        plt.figure(figsize=(12, 4))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'], label='accuracy')
        plt.plot(history.history['val_accuracy'], label='val_accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend()
        
        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'], label='loss')
        plt.plot(history.history['val_loss'], label='val_loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend()
        
        plt.tight_layout()
        
        # Save the training history
        if save_path:
            plt.savefig(os.path.join(os.path.dirname(save_path), 'training_history.png'))
        
        plt.show()
        
        # Save model if requested
        if save_path:
            self.model.save(save_path)
            print(f"Model saved to {save_path}")
        
        return history
    
    def load_model(self, model_path):
        """Load a pre-trained model"""
        self.model = models.load_model(model_path)
        print(f"Model loaded from {model_path}")
        
        # Try to load class names if they exist alongside the model
        class_names_path = os.path.join(os.path.dirname(model_path), 'class_names.txt')
        if os.path.exists(class_names_path):
            with open(class_names_path, 'r') as f:
                self.class_names = [line.strip() for line in f.readlines()]
            print(f"Loaded {len(self.class_names)} class names")
    
    def predict(self, image):
        """
        Predict the ASL letter from an image
        Returns letter and confidence level (0-1)
        """
        if self.model is None:
            raise ValueError("Model not loaded or trained")
        
        if len(self.class_names) == 0:
            raise ValueError("Class names not available")
        
        # Preprocess the image
        processed_img = cv2.resize(image, (64, 64))
        if len(processed_img.shape) == 3:
            processed_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)
        
        processed_img = processed_img / 255.0
        processed_img = processed_img.reshape(1, 64, 64, 1)
        
        # Get prediction
        predictions = self.model.predict(processed_img)[0]
        predicted_idx = np.argmax(predictions)
        confidence = float(predictions[predicted_idx])
        
        return self.class_names[predicted_idx], confidence
    
    def predict_top_k(self, image, k=3):
        """
        Predict the top-k most likely ASL letters from an image.
        Returns a list of (class_name, confidence) pairs, sorted by confidence desc.
        """
        if self.model is None:
            raise ValueError("Model not loaded or trained")
        
        if len(self.class_names) == 0:
            raise ValueError("Class names not available")
        
        # Preprocess the image
        processed_img = cv2.resize(image, (64, 64))
        if len(processed_img.shape) == 3:
            processed_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)
        
        processed_img = processed_img / 255.0
        processed_img = processed_img.reshape(1, 64, 64, 1)
        
        # Get prediction (softmax output)
        predictions = self.model.predict(processed_img)[0]  # shape (26,)
        # Sort in ascending order, take top k in descending order
        top_k_indices = predictions.argsort()[-k:][::-1]
        
        top_k_list = [(self.class_names[idx], float(predictions[idx])) for idx in top_k_indices]
        return top_k_list
    
    def save_class_names(self, save_dir):
        """Save class names to a file"""
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
            
        with open(os.path.join(save_dir, 'class_names.txt'), 'w') as f:
            for class_name in self.class_names:
                f.write(f"{class_name}\n")


def main():
    # Path to dataset
    dataset_path = "src/aslwireframemodified"
    
    # Create model directory if it doesn't exist
    model_dir = "models"
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
    
    model_path = os.path.join(model_dir, "asl_model.h5")
    
    # Check if model already exists
    if os.path.exists(model_path):
        print(f"Loading existing model from {model_path}")
        recognizer = ASLRecognizer(model_path)
    else:
        print("Creating and training new model")
        recognizer = ASLRecognizer()
        recognizer.train(dataset_path, epochs=20, save_path=model_path)
        recognizer.save_class_names(model_dir)
    
    # Test with webcam (optional)
    cap = cv2.VideoCapture(0)
    
    while True:
        success, img = cap.read()
        if not success:
            print("Failed to grab frame")
            break
        
        # Make a copy for prediction (grayscale)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        try:
            letter, confidence = recognizer.predict(gray)
            cv2.putText(img, f"{letter} ({confidence:.2f})", (50, 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        except Exception as e:
            print(f"Prediction error: {e}")
        
        cv2.imshow("ASL Recognition Test", img)
        if cv2.waitKey(1) == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main() 